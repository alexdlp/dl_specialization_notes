[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ".",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "Convolutional_Neural_Networks.html#contenidos",
    "href": "Convolutional_Neural_Networks.html#contenidos",
    "title": "1  Redes neuronales convolucionales: paso a paso",
    "section": "1.1 Contenidos",
    "text": "1.1 Contenidos\n\n1 - Librerías\n2 - Convolutional Neural Networks\n\n2.1 - Zero-Padding\n\n\n ## 1 - Librerías\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n%load_ext autoreload\n%autoreload 2\n\nnp.random.seed(1)\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "Convolutional_Neural_Networks.html#convolutional-neural-networks",
    "href": "Convolutional_Neural_Networks.html#convolutional-neural-networks",
    "title": "1  Redes neuronales convolucionales: paso a paso",
    "section": "1.2 2 - Convolutional Neural Networks",
    "text": "1.2 2 - Convolutional Neural Networks\nUna capa de convolución transforma un volumen de entrada en un volumen de salida de tamaño diferente, como se muestra a continuación:\n\n\n\nEn esta parte, se construirán todos los pasos de la capa de convolución. Se comenzará implementando dos funciones auxiliares: una para el zero-padding y otra para calcular la función de convolución en sí.\n\n\n1.2.1 2.1 - Zero-Padding\n\n\n\n\n Figure 1:  Zero-Padding Image (3 channels, RGB) with a padding of 2.\n\n\n\nLos principales beneficios del padding son:\nPermite utilizar una capa CONV sin reducir necesariamente la altura y el ancho de los volúmenes. Esto es importante para construir redes más profundas, ya que de lo contrario, la altura y el ancho disminuirían al avanzar hacia capas más profundas. Un caso especial importante es la convolución “same”, en la que la altura y el ancho se preservan exactamente después de una capa.\nAyuda a conservar más información en el borde de una imagen. Sin relleno, muy pocos valores en la capa siguiente se verían afectados por los píxeles en los bordes de una imagen.\n\n\n\n1.2.2 Ejercicio 1 - zero_pad\nSe debe implementar la siguiente función, que añade zero-padding a todas las imágenes de un batch de ejemplos X.\nPor ejemplo, si se desea añadir un relleno de pad = 1 para la segunda dimensión, pad = 3 para la cuarta dimensión y pad = 0 para el resto a un array “a” de forma \\((5,5,5,5,5)\\), se haría de la siguiente manera:\na = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), mode='constant', constant_values = (0,0))\n\ndef zero_pad(X, pad):\n    \"\"\"\n    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n    as illustrated in Figure 1.\n    \n    Argument:\n    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n    \n    Returns:\n    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n    \"\"\"\n    \n    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)))\n      \n    return X_pad\n\n\n# genero vector de números aleatorios (4 matrices de 3x3 con 2 canales)\nx = np.random.randn(4, 3, 3, 2)\n\n# le añado el padding (El tamaño del relleno es 3, lo que significa que se añaden 3 filas/columnas de ceros alrededor de cada matriz)\nx_pad = zero_pad(x, 3)\n\nprint (f\"Dimensiones del vector x: \\t{x.shape}\")\nprint (f\"Dimensiones del vector x_pad: \\t{x.shape}\")\n\nprint (\"\\nContenido de x[1,1] =\\n\", x[1, 1])\nprint (\"\\nContenido de x_pad[1,1] =\\n\", x_pad[1, 1])\n\nfig, axarr = plt.subplots(1, 2)\naxarr[0].set_title('x')\naxarr[0].imshow(x[0, :, :, 0])\naxarr[1].set_title('x_pad')\naxarr[1].imshow(x_pad[0, :, :, 0])\nplt.show()\n\nDimensiones del vector x:   (4, 3, 3, 2)\nDimensiones del vector x_pad:   (4, 3, 3, 2)\n\nContenido de x[1,1] =\n [[-0.34385368  0.04359686]\n [-0.62000084  0.69803203]\n [-0.44712856  1.2245077 ]]\n\nContenido de x_pad[1,1] =\n [[0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]]\n\n\n\n\n\n\n\n\n1.2.3 2.2 - Un solo paso de la convolución\nEn esta parte, se implementará un solo paso de la convolución, en el cual se aplciará el filtro a una única posición de la entrada. Esto se utilizará para construir una unidad convolucional, que:\n\nToma un volumen de entrada\nAplica un filtro en cada posición de la entrada\nProduce otro volumen (generalmente de tamaño diferente)\n\n\n\n\n\n Figura 2:  Operación de convolución Operación de convolución con un filtro de 3x3 y un paso de 1 (el paso es la cantidad que mueves la ventana cada vez que la deslizas)\n\n\n\nEn una aplicación de computer vision, cada valor en la matriz de la izquierda corresponde a un solo valor de píxel. Se convoluciona un filtro de 3x3 con la imagen multiplicando sus valores elemento a elemento (element-wise) con la matriz original, luego sumándolos y añadiendo un sesgo (bias). En este primer paso, se implementa un solo paso de la convolución, correspondiente a aplicar un filtro a solo una de las posiciones para obtener una única salida de valor real.\n\n\n\n1.2.4 Ejercicio 2 - conv_single_step\nImplementa conv_single_step().\n\ndef conv_single_step(a_slice_prev, W, b):\n    \"\"\"\n    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n    of the previous layer.\n    \n    Arguments:\n    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n    \n    Returns:\n    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n    \"\"\"\n\n    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n    s = np.multiply(a_slice_prev,W)\n    # Sum over all entries of the volume s.\n    Z = np.sum(s)\n    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n    b = np.squeeze(b)\n    Z = Z + b\n    \n    return Z\n\n\na_slice_prev = np.random.randn(4, 4, 3)\nW = np.random.randn(4, 4, 3)\nb = np.random.randn(1, 1, 1)\n\nZ = conv_single_step(a_slice_prev, W, b)\nprint(\"Z =\", Z)\n\nZ = -6.999089450680221\n\n\n\n\n\n1.2.5 2.3 - Convolutional Neural Networks - Forward Pass\nEn el forward pass, se convolucionan múltiples filtros sobre la entrada. Cada ‘convolución’ proporciona una salida en forma de matriz 2D. Estas salidas se apilan para obtener un volumen 3D:\n\n\n\n\n\n\n\n1.2.6 Exercise 3 - conv_forward\nSe implementará la función a continuación para convolucionar los filtros W sobre una activación de entrada A_prev. Esta función toma los siguientes parámetros:\n\nA_prev, las activaciones producidas por la capa anterior (para un batc de \\(m\\) entradas);\nLos pesos se denotan con W. El tamaño de la ventana del filtro es \\(f x f\\) .\nEl vector de sesgo es b, donde cada filtro tiene su propio sesgo (único). También se tiene acceso al diccionario de hiperparámetros, que contiene el paso (stride) y el relleno (padding).\n\nHint: 1. To select a 2x2 slice at the upper left corner of a matrix “a_prev” (shape (5,5,3)), you would do:\na_slice_prev = a_prev[0:2,0:2,:]\nNotice how this gives a 3D slice that has height 2, width 2, and depth 3. Depth is the number of channels.\nThis will be useful when you will define a_slice_prev below, using the start/end indexes you will define.\n\nTo define a_slice you will need to first define its corners vert_start, vert_end, horiz_start and horiz_end. This figure may be helpful for you to find out how each of the corners can be defined using h, w, f and s in the code below.\n\n\n\n\n  Figure 3  : Definition of a slice using vertical and horizontal start/end (with a 2x2 filter)  This figure shows only a single channel.\n\n\nReminder:\nThe formulas relating the output shape of the convolution to the input shape are:\n\\[n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1\\] \\[n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1\\] \\[n_C = \\text{number of filters used in the convolution}\\]\nFor this exercise, don’t worry about vectorization! Just implement everything with for-loops."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "sine_wave.html",
    "href": "sine_wave.html",
    "title": "3  Shinylive in Quarto example",
    "section": "",
    "text": "This is a Shinylive application embedded in a Quarto doc.\nThe plot below allows you to control parameters used in the sine function. Experiment with the period, amplitude, and phase shift to see how they affect the graph.\n#| standalone: true\n#| viewerHeight: 420\n\nfrom shiny import App, render, ui\nimport numpy as np\nimport matplotlib.pyplot as plt\n\napp_ui = ui.page_fluid(\n    ui.layout_sidebar(\n        ui.panel_sidebar(\n            ui.input_slider(\"period\", \"Period\", 0.5, 2, 1, step=0.01),\n            ui.input_slider(\"amplitude\", \"Amplitude\", 0, 2, 1, step=0.25),\n            ui.input_slider(\"shift\", \"Phase shift\", 0, 2, 0, step=0.1),\n        ),\n        ui.panel_main(\n            ui.output_plot(\"plot\"),\n        ),\n    ),\n)\n\n\ndef server(input, output, session):\n    @output\n    @render.plot(alt=\"Sine function\")\n    def plot():\n        t = np.arange(0.0, 4.0, 0.01)\n        s = input.amplitude() * np.sin(\n            (2 * np.pi / input.period()) * (t - input.shift() / 2)\n        )\n        fig, ax = plt.subplots()\n        ax.set_ylim([-2, 2])\n        ax.plot(t, s)\n        ax.grid()\n\n\napp = App(app_ui, server)"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]