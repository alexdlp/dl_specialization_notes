[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ".",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "sine_wave.html",
    "href": "sine_wave.html",
    "title": "2  Shinylive in Quarto example",
    "section": "",
    "text": "This is a Shinylive application embedded in a Quarto doc.\n#| standalone: true\n\nfrom shiny import *\n\napp_ui = ui.page_fluid(\n    ui.input_slider(\"n\", \"N\", 0, 100, 40),\n    ui.output_text_verbatim(\"txt\"),\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def txt():\n        return f\"The value of n*2 is {input.n() * 2}\"\n\napp = App(app_ui, server)"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "Convolutional_Neural_Networks.html#contenidos",
    "href": "Convolutional_Neural_Networks.html#contenidos",
    "title": "1  Redes neuronales convolucionales: paso a paso",
    "section": "2.1 Contenidos",
    "text": "2.1 Contenidos\n\n1 - Librerías\n2 - Convolutional Neural Networks\n\n2.1 - Zero-Padding\n\nExercise 1 - zero_pad\n\n2.2 - Single Step of Convolution\n\nExercise 2 - conv_single_step\n\n2.3 - Convolutional Neural Networks - Forward Pass\n\nExercise 3 - conv_forward"
  },
  {
    "objectID": "Convolutional_Neural_Networks.html#librerías",
    "href": "Convolutional_Neural_Networks.html#librerías",
    "title": "1  Redes neuronales convolucionales: paso a paso",
    "section": "2.2 1 - Librerías",
    "text": "2.2 1 - Librerías\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n\nnp.random.seed(1)"
  },
  {
    "objectID": "Convolutional_Neural_Networks.html#convolutional-neural-networks",
    "href": "Convolutional_Neural_Networks.html#convolutional-neural-networks",
    "title": "1  Redes neuronales convolucionales: paso a paso",
    "section": "2.3 2 - Convolutional Neural Networks",
    "text": "2.3 2 - Convolutional Neural Networks\nUna capa de convolución transforma un volumen de entrada en un volumen de salida de tamaño diferente, como se muestra a continuación:\n\n\n\nEn esta parte, se construirán todos los pasos de la capa de convolución. Se comenzará implementando dos funciones auxiliares: una para el zero-padding y otra para calcular la función de convolución en sí.\n\n\n2.3.1 2.1 - Zero-Padding\n\n\n\n\n Figure 1:  Zero-Padding Image (3 channels, RGB) with a padding of 2.\n\n\n\nLos principales beneficios del padding son:\nPermite utilizar una capa CONV sin reducir necesariamente la altura y el ancho de los volúmenes. Esto es importante para construir redes más profundas, ya que de lo contrario, la altura y el ancho disminuirían al avanzar hacia capas más profundas. Un caso especial importante es la convolución “same”, en la que la altura y el ancho se preservan exactamente después de una capa.\nAyuda a conservar más información en el borde de una imagen. Sin relleno, muy pocos valores en la capa siguiente se verían afectados por los píxeles en los bordes de una imagen.\n\n\n\n2.3.2 Ejercicio 1 - zero_pad\nSe debe implementar la siguiente función, que añade zero-padding a todas las imágenes de un batch de ejemplos X.\nPor ejemplo, si se desea añadir un relleno de pad = 1 para la segunda dimensión, pad = 3 para la cuarta dimensión y pad = 0 para el resto a un array “a” de forma \\((5,5,5,5,5)\\), se haría de la siguiente manera:\na = np.pad(a, ((0,0), (1,1), (0,0), (3,3), (0,0)), mode='constant', constant_values = (0,0))\n\n\nCode\ndef zero_pad(X, pad):\n    \"\"\"\n    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, \n    as illustrated in Figure 1.\n    \n    Argument:\n    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n    \n    Returns:\n    X_pad -- padded image of shape (m, n_H + 2 * pad, n_W + 2 * pad, n_C)\n    \"\"\"\n    \n    X_pad = np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)))\n      \n    return X_pad\n\n\n\n\nCode\n# genero vector de números aleatorios (4 matrices de 3x3 con 2 canales)\nx = np.random.randn(4, 3, 3, 2)\n\n# le añado el padding (El tamaño del relleno es 3, lo que significa que se añaden 3 filas/columnas de ceros alrededor de cada matriz)\nx_pad = zero_pad(x, 3)\n\nprint (f\"Dimensiones del vector x: \\t{x.shape}\")\nprint (f\"Dimensiones del vector x_pad: \\t{x.shape}\")\n\nprint (\"\\nContenido de x[1,1] =\\n\", x[1, 1])\nprint (\"\\nContenido de x_pad[1,1] =\\n\", x_pad[1, 1])\n\nfig, axarr = plt.subplots(1, 2)\naxarr[0].set_title('x')\naxarr[0].imshow(x[0, :, :, 0])\naxarr[1].set_title('x_pad')\naxarr[1].imshow(x_pad[0, :, :, 0])\nplt.show()\n\n\nDimensiones del vector x:   (4, 3, 3, 2)\nDimensiones del vector x_pad:   (4, 3, 3, 2)\n\nContenido de x[1,1] =\n [[ 0.90085595 -0.68372786]\n [-0.12289023 -0.93576943]\n [-0.26788808  0.53035547]]\n\nContenido de x_pad[1,1] =\n [[0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]]\n\n\n\n\n\n\n\nCode\nx[1,:,:,:]\n\n\narray([[[ 0.04221375,  0.58281521],\n        [-1.10061918,  1.14472371],\n        [ 0.90159072,  0.50249434]],\n\n       [[ 0.90085595, -0.68372786],\n        [-0.12289023, -0.93576943],\n        [-0.26788808,  0.53035547]],\n\n       [[-0.69166075, -0.39675353],\n        [-0.6871727 , -0.84520564],\n        [-0.67124613, -0.0126646 ]]])\n\n\n\n\n\n2.3.3 2.2 - Un solo paso de la convolución\nEn esta parte, se implementará un solo paso de la convolución, en el cual se aplciará el filtro a una única posición de la entrada. Esto se utilizará para construir una unidad convolucional, que:\n\nToma un volumen de entrada\nAplica un filtro en cada posición de la entrada\nProduce otro volumen (generalmente de tamaño diferente)\n\n\n\n\n\n Figura 2:  Operación de convolución Operación de convolución con un filtro de 3x3 y un paso de 1 (el paso es la cantidad que mueves la ventana cada vez que la deslizas)\n\n\n\nEn una aplicación de computer vision, cada valor en la matriz de la izquierda corresponde a un solo valor de píxel. Se convoluciona un filtro de 3x3 con la imagen multiplicando sus valores elemento a elemento (element-wise) con la matriz original, luego sumándolos y añadiendo un sesgo (bias). En este primer paso, se implementa un solo paso de la convolución, correspondiente a aplicar un filtro a solo una de las posiciones para obtener una única salida de valor real.\n\n\n\n2.3.4 Ejercicio 2 - conv_single_step\nImplementa conv_single_step().\n\n\nCode\ndef conv_single_step(a_slice_prev, W, b):\n    \"\"\"\n    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation \n    of the previous layer.\n    \n    Arguments:\n    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n    \n    Returns:\n    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n    \"\"\"\n\n    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n    s = np.multiply(a_slice_prev,W)\n    # Sum over all entries of the volume s.\n    Z = np.sum(s)\n    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n    b = np.squeeze(b)\n    Z = Z + b\n    \n    return Z\n\n\n\n\nCode\na_slice_prev = np.random.randn(4, 4, 3)\nW = np.random.randn(4, 4, 3)\nb = np.random.randn(1, 1, 1)\n\nZ = conv_single_step(a_slice_prev, W, b)\nprint(\"Z =\", Z)\n\n\nZ = 0.35608282827551285\n\n\n\n\n\n2.3.5 2.3 - Convolutional Neural Networks - Forward Pass\nEn el forward pass, se convolucionan múltiples filtros sobre la entrada. Cada ‘convolución’ proporciona una salida en forma de matriz 2D. Estas salidas se apilan para obtener un volumen 3D:\n\n\n\n\n\n\n\n2.3.6 Exercise 3 - conv_forward\nSe implementará la función a continuación para convolucionar los filtros W sobre una activación de entrada A_prev. Esta función toma los siguientes parámetros:\n\nA_prev, las activaciones producidas por la capa anterior (para un batc de \\(m\\) entradas);\nLos pesos se denotan con W. El tamaño de la ventana del filtro es \\(f x f\\) .\nEl vector de sesgo es b, donde cada filtro tiene su propio sesgo (único). También se tiene acceso al diccionario de hiperparámetros, que contiene el paso (stride) y el relleno (padding).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nHint: 1. Para seleccionar una porción 2x2 en la esquina superior izquierda de una matriz “a_prev” (de forma (5,5,3)), se haría:\na_slice_prev = a_prev[0:2,0:2,:]\nNotese cómo esto da una porción 3D que tiene altura 2, ancho 2 y profundidad 3. La profundidad es el número de canales.\nEsto será útil cuando se defina a_slice_prev a continuación, utilizando los índices start/end que se definirán.\n\nPara definir a_slice se necesitará primero definir sus esquinas vert_start, vert_end, horiz_start y horiz_end. La siguiente figura puede ser útil para descubrir cómo cada una de las esquinas puede ser definida usando \\(h\\), \\(w\\), \\(f\\) y \\(s\\) en el código a continuación.\n\n\n\n\n\n Figura 3:  Definition of a slice using vertical and horizontal start/end (with a 2x2 filter)  This figure shows only a single channel.\n\n\n\n\nReminder:\nLas fórmulas que relacionan la forma de salida de la convolución con la forma de entrada son:\n\\[n_H = \\Bigl\\lfloor \\frac{n_{H_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1\\] \\[n_W = \\Bigl\\lfloor \\frac{n_{W_{prev}} - f + 2 \\times pad}{stride} \\Bigr\\rfloor +1\\] \\[n_C = \\text{número de filtros en la convolución}\\]\n\n\n\nPara este ejercicio se implementará todo con bucles for.\n\n\nCode\ndef conv_forward(A_prev, W, b, hparameters):\n    \"\"\"\n    Implements the forward propagation for a convolution function\n    \n    Arguments:\n    A_prev -- output activations of the previous layer, \n        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n    hparameters -- python dictionary containing \"stride\" and \"pad\"\n        \n    Returns:\n    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n    cache -- cache of values needed for the conv_backward() function\n    \"\"\"\n    \n    # Retrieve dimensions from A_prev's shape (≈1 line)  \n    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n    \n    # Retrieve dimensions from W's shape (≈1 line)\n    (f, f, n_C_prev, n_C) = W.shape\n    \n    # Retrieve information from \"hparameters\" (≈2 lines)\n    stride = hparameters[\"stride\"]\n    pad = hparameters[\"pad\"]\n    \n    # Compute the dimensions of the CONV output volume using the formula given above. \n    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n    n_H = int((n_H_prev + 2*pad - f)/stride) + 1\n    n_W = int((n_W_prev + 2*pad - f)/stride) + 1\n    \n    # Initialize the output volume Z with zeros. (≈1 line)\n    Z = np.zeros((m, n_H, n_W, n_C))\n    \n    # Create A_prev_pad by padding A_prev\n    A_prev_pad = zero_pad(A_prev, pad)\n    \n    for i in range(m):               # loop over the batch of training examples\n        a_prev_pad = A_prev_pad[i]          # Select ith training example's padded activation\n        for h in range(n_H):           # loop over vertical axis of the output volume\n            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n            vert_start = stride * h \n            vert_end = vert_start  + f\n            \n            for w in range(n_W):       # loop over horizontal axis of the output volume\n                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n                horiz_start = stride * w\n                horiz_end = horiz_start + f\n                \n                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n                                        \n                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n                    a_slice_prev = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n                    \n                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n                    weights = W[:, :, :, c]\n                    biases  = b[:, :, :, c]\n                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n    \n    # Save information in \"cache\" for the backprop\n    cache = (A_prev, W, b, hparameters)\n    \n    return Z, cache\n\n\n\n\nCode\nnp.random.seed(1)\nA_prev = np.random.randn(2, 5, 7, 4)\nW = np.random.randn(3, 3, 4, 8)\nb = np.random.randn(1, 1, 1, 8)\nhparameters = {\"pad\" : 1,\n               \"stride\": 2}\n\nZ, cache_conv = conv_forward(A_prev, W, b, hparameters)\nprint(\"\\nZ's mean =\\t\", np.mean(Z))\nprint(\"\\nZ[0,2,1] =\\n\", Z[0, 2, 1])\nprint(\"\\ncache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])\n\n\n\nZ's mean =   0.5511276474566768\n\nZ[0,2,1] =\n [-2.17796037  8.07171329 -0.5772704   3.36286738  4.48113645 -2.89198428\n 10.99288867  3.03171932]\n\ncache_conv[0][1][2][3] =\n [-1.1191154   1.9560789  -0.3264995  -1.34267579]"
  },
  {
    "objectID": "Convolutional_Neural_Networks.html",
    "href": "Convolutional_Neural_Networks.html",
    "title": "1  Redes neuronales convolucionales: paso a paso",
    "section": "",
    "text": "2 Redes neuronales convolucionales: paso a paso\nEsta es la primera tarea del Curso 4. En esta tarea se implementan capas de convolución (CONV) y de pooling (POOL) en numpy, incluyendo tanto el fordward propagation como el backward propagation.\nAl final de este cuaderno, serás capaz de:"
  }
]